#!/bin/bash
set -euo pipefail

ENV_PATH=$(poetry env info --path 2>/dev/null)

LLAMA_DIR="/home/olmorera/AI/llama.cpp"
LIB_PATH="$LLAMA_DIR/build/bin/libllama.so"

echo "ğŸ§¹ Removing previous llama.cpp build..."
rm -rf "$LLAMA_DIR"

echo "â¬‡ï¸ Cloning llama-cpp-python with kv-cache compatible submodule..."
git clone --recurse-submodules https://github.com/abetlen/llama-cpp-python.git "$LLAMA_DIR"
cd "$LLAMA_DIR"

echo "ğŸ“Œ Checking out version compatible with llama_kv_cache_view_init..."
git checkout v0.3.9
git submodule update --init --recursive

echo "ğŸ§  Configuring build with shared library and CPU optimizations..."
cmake -S . -B build \
  -DCMAKE_BUILD_TYPE=Release \
  -DBUILD_SHARED_LIBS=ON \
  -DLLAMA_BUILD_TESTS=OFF

echo "ğŸš€ Compiling llama.cpp using $(nproc) cores..."
cmake --build build --config Release -j"$(nproc)"

echo "ğŸ” Verifying libllama.so at: $LIB_PATH"
if [[ ! -f "$LIB_PATH" ]]; then
  echo "âŒ ERROR: libllama.so not found at $LIB_PATH"
  exit 1
fi

echo "ğŸ” Verifying presence of symbol: llama_kv_cache_view_init..."
if nm -D "$LIB_PATH" | grep 'llama_kv_cache_view_init' > /dev/null; then
  echo "âœ… Symbol 'llama_kv_cache_view_init' found in libllama.so"
else
  echo "âŒ ERROR: Symbol 'llama_kv_cache_view_init' NOT found in libllama.so"
  echo "ğŸ’¡ llama-cpp-python >= 0.3.9 will fail without this"
  exit 1
fi

# Export before install
export LLAMA_CPP_LIB="$LIB_PATH"

echo "ğŸ“¦ Optional: Reinstall llama-cpp-python from local source?"
read -rp "ğŸ” Reinstall llama-cpp-python now? [y/N]: " REPLY
if [[ "$REPLY" =~ ^[Yy]$ ]]; then
  pip uninstall -y llama-cpp-python || true
  pip install . --no-deps
  echo "âœ… llama-cpp-python installed from local source."
fi

# Persist LLAMA_CPP_LIB in ~/.bashrc
if grep -q "^export LLAMA_CPP_LIB=" ~/.bashrc; then
  echo "ğŸ” Updating existing LLAMA_CPP_LIB in ~/.bashrc..."
  sed -i "s|^export LLAMA_CPP_LIB=.*|export LLAMA_CPP_LIB=\"$LIB_PATH\"|" ~/.bashrc
else
  echo "ğŸ“ Adding LLAMA_CPP_LIB to ~/.bashrc..."
  echo "export LLAMA_CPP_LIB=\"$LIB_PATH\"" >> ~/.bashrc
fi

if [[ -z "$ENV_PATH" ]]; then
  echo ""
  echo "âš ï¸  Poetry virtual environment not found."
  echo "   Please run the following first to create it:"
  echo ""
  echo "   poetry install"
  echo ""
  echo "ğŸ” Then, re-run this script or manually do:"
  echo "   source ~/.bashrc && source \$(poetry env info --path)/bin/activate"
  echo "   poetry run pip install /home/olmorera/AI/llama.cpp --no-deps"
  echo ""
else
  echo ""
  echo "ğŸ”„ To apply the environment and use llama-cpp-python, run:"
  echo ""
  echo "   source ~/.bashrc && source \"$ENV_PATH/bin/activate\""
  echo ""
  echo "ğŸ“¦ Then run inside the project:"
  echo ""
  echo "   poetry run pip uninstall -y llama-cpp-python || true"
  echo "   poetry run pip cache purge"
  echo "   poetry run pip install /home/olmorera/AI/llama.cpp --no-deps"
  echo ""
fi

echo "ğŸ‰ Done!"

